import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# GPT ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.4)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë³´ì•ˆ ìë™í™” ì „ë¬¸ê°€ë¡œ ì„¤ì •)
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", 
     "ë„ˆëŠ” ë¦¬ëˆ…ìŠ¤, ìœˆë„ìš° ì„œë²„ ë³´ì•ˆ ë° ì¸í”„ë¼ ìë™í™” ì „ë¬¸ê°€ì•¼. "
     "CCE ê¸°ë°˜ ì·¨ì•½ì  ì§„ë‹¨, Ansibleì„ í™œìš©í•œ ì„œë²„ ë³´ì•ˆ ì ê²€ ìë™í™”, "
     "OSë³„ íŒ¨í‚¤ì§€ ê´€ë¦¬, SSH ì„¤ì •, ì‹œìŠ¤í…œ ë¡œê·¸ ë¶„ì„, ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ ì ê²€ ë“±ì— ëŒ€í•œ "
     "ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µí•´ì¤˜."),
    ("user", "{question}")
])

# ì²´ì¸ ìƒì„±
chain = chat_prompt | llm

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë³´ì•ˆ ìë™í™” ì±—ë´‡", page_icon="ğŸ›¡ï¸", layout="centered")

# ğŸ”§ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ ì¡°ì • (í°íŠ¸ í¬ê¸°/ì¤„ ê°„ê²©)
st.markdown("""
<style>
.chat-message p {
    font-size: 14px !important;
    line-height: 1.6 !important;
    margin-bottom: 10px;
}
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# íƒ€ì´í‹€
st.title("ğŸ›¡ï¸ ë³´ì•ˆ ìë™í™” AI ì±—ë´‡")
st.write("Ubuntu, CentOS, Windows Server ê¸°ë°˜ ë³´ì•ˆ ì ê²€ ë° Ansible ìë™í™” ê´€ë ¨ ì§ˆë¬¸ì„ ììœ ë¡­ê²Œ í•˜ì„¸ìš”.")

# ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ë³´ì•ˆ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”.")
if user_input:
    st.session_state.messages.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        try:
            response = chain.invoke({"question": user_input})
            result = response.content
        except Exception as e:
            result = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"

    st.session_state.messages.append(AIMessage(content=result))
    with st.chat_message("assistant"):
        st.markdown(result)